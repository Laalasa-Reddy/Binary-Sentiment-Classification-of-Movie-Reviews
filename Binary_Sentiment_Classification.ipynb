{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9553cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Load the IMDb dataset or replace it with your own dataset\n",
    "df = pd.read_csv('IMDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fe0fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "258d1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target (y)\n",
    "X = df['review'].values\n",
    "y = df['sentiment'].values\n",
    "\n",
    "# Preprocess the text data using TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73361b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1cd86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6521739130434783\n",
      "F1 Score: 0.6172360248447205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.89      0.75        27\n",
      "    positive       0.67      0.32      0.43        19\n",
      "\n",
      "    accuracy                           0.65        46\n",
      "   macro avg       0.66      0.60      0.59        46\n",
      "weighted avg       0.66      0.65      0.62        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e87eb370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\laala\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\laala\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\laala\\anaconda3\\lib\\site-packages (from xgboost) (1.22.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6724c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5005d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the IMDb dataset or replace it with your own dataset\n",
    "df = pd.read_csv('IMDB.csv')\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df['review'].values\n",
    "y = df['sentiment'].values\n",
    "\n",
    "# Encode the target variable into numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Preprocess the text data using TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b3b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBClassifier\n",
    "xgb_clf = XGBClassifier(objective='binary:logistic', eval_metric='logloss', max_depth=6, learning_rate=0.1, n_estimators=100, n_jobs=-1, random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b7cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6739130434782609\n",
      "F1 Score: 0.6685191238966981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.78      0.74        27\n",
      "    positive       0.62      0.53      0.57        19\n",
      "\n",
      "    accuracy                           0.67        46\n",
      "   macro avg       0.66      0.65      0.65        46\n",
      "weighted avg       0.67      0.67      0.67        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Decode the numerical labels back to original labels if needed\n",
    "y_test_original = label_encoder.inverse_transform(y_test)\n",
    "y_pred_original = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1a1de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.4011 - accuracy: 0.8276 - val_loss: 0.2609 - val_accuracy: 0.8948\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.2104 - accuracy: 0.9210 - val_loss: 0.2632 - val_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.1494 - accuracy: 0.9462 - val_loss: 0.2910 - val_accuracy: 0.8923\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.1019 - accuracy: 0.9658 - val_loss: 0.3426 - val_accuracy: 0.8900\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0679 - accuracy: 0.9772 - val_loss: 0.4096 - val_accuracy: 0.8851\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0503 - accuracy: 0.9834 - val_loss: 0.4616 - val_accuracy: 0.8831\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0394 - accuracy: 0.9862 - val_loss: 0.5118 - val_accuracy: 0.8829\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0332 - accuracy: 0.9883 - val_loss: 0.5196 - val_accuracy: 0.8814\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.5564 - val_accuracy: 0.8795\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.6282 - val_accuracy: 0.8750\n",
      "accuracy: 0.8859099924564362\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# Load the IMDB dataset\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# Concatenate the training and testing data and targets\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "# Vectorize the data\n",
    "def vectorize(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "data = vectorize(data)\n",
    "targets = np.array(targets).astype(\"float32\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "test_x = data[:10000]\n",
    "test_y = targets[:10000]\n",
    "train_x = data[10000:]\n",
    "train_y = targets[10000:]\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation=\"relu\", input_shape=(10000,)))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "results = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=10,\n",
    "    batch_size=500,\n",
    "    validation_data=(test_x, test_y),\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"accuracy:\", np.mean(results.history['val_accuracy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f8875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
